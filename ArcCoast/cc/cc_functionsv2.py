import urllib.request
import numpy as np
import pickle
import matplotlib.pyplot as plt
from osgeo import gdal
import os, glob, shutil, subprocess, copy
import shapefile
import scipy.stats as st
import datetime
from scipy.spatial.transform import Rotation as R
from shapely.geometry import LineString
from scipy.spatial.distance import directed_hausdorff
import matplotlib.image as mpimg


# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY
# CALLED DIRECTLY



def FindEPSG2(filepath):

# this function finds the epsg code for the projection of the region by looking at the images downloaded from GEE


    nums = ['1','2','3','4','5','6','7','8','9','0']
    a = glob.glob(filepath + "\\L8\\pan\\*")
    b = glob.glob(filepath + "\\S2\\ms\\*")
    c = a+b
    epsgs = []
    for aa in c[1:2]:
        
        
        blocks = gdal.Info(a[0], format='json')['coordinateSystem']['wkt'].split('\n')
        blocks.reverse()
        for block in blocks:
            if 'EPSG' in block:
                break
        for char in block:
            if char not in nums:
                block = block.replace(char,'')    
        
        image_epsg = int(block)
        epsgs.append(image_epsg)
    return epsgs[0]


def AdjustOutputShapefileByTides5(slope_ests,output,filepath,sitename,Contour,transects):


# this function shifts the land/water interfaces generated by coastsat up or down the beach slope according to tidal elevations
# it moves the shoreline perpendicular to the slope of the entire shoreline, not a local area. This means lines with regions that are not parallel to the overall slope of the shore are distorted in their shift:
# use caution for heavily curved or convoluted shoresShapefile
# consider breaking them into smaller sections

    
    # for the chosen point along the reference shoreline find a slope for best fit line
    shoreshape = shapefile.Reader(filepath+"\\"+sitename+"_reference_shoreline.shp")
    shoreRece = shoreshape.shapeRecords()[0]
    shorepoints=shoreRece.shape.points
    shoreshape.close()
    
    deriv_points = np.array(shorepoints)
    x = deriv_points[:,0]
    y = deriv_points[:,1]
    slope, intercept, r_value, p_value, std_err = st.linregress(x, y)
    
    # find a slope perpindicular to shorelne slope for transect
    pslope = -1*(1/slope)
    angle = np.arctan(pslope)
    
    # find beach slope
    slopes = []
    for slope_est in slope_ests:
        slopes.append(slope_ests[slope_est])
    slope = np.nanmean(np.array(slopes))
    
    # Get point from ocean
    shoreRece = list(transects.keys())[int(len(transects)/2)]
    ocean_lat_long=transects[shoreRece][0]
    
    # open trimmed shorelines and start tidally corrected shorelines file
    shoreshape = shapefile.Reader(filepath+"\\"+sitename+"_outputTrim.shp")
    shoreRecs = shoreshape.shapeRecords()
    w = shapefile.Writer(filepath+"\\"+sitename+"_outputTidalC.shp")
    w.fields = shoreshape.fields[1:]    
    
    newshores=[]
    for shoreRec in shoreRecs:
        shorepoints = shoreRec.shape.points
        
        # find tide position
        date = shoreRec.record[0]
        days = []
        months = []
        years = []
        for fdgfd in output['dates']:
            days.append(fdgfd.day==date.day)
            months.append(fdgfd.month==date.month)
            years.append(fdgfd.year==date.year)
            
        for n in range(0,len(days)):
            if days[n] and months[n] and years[n]:
                break

        Vdistance = -output['tides'][n] + Contour
        Hshift = Vdistance/slope

        if Hshift>0:
            outTOsea=False
        if Hshift<0:
            outTOsea=True
            
        shorepoints1 = np.array(shorepoints)
        shorepoints2 = np.dstack((shorepoints1[:,0] + np.cos(angle) * Hshift, shorepoints1[:,1] + np.sin(angle) * Hshift))[0]
        shorepoints3 = np.dstack((shorepoints1[:,0] + np.cos(angle) * -Hshift, shorepoints1[:,1] + np.sin(angle) * -Hshift))[0]

        testpoint1 = shorepoints2[int(len(shorepoints2)/2)]
        testpoint2 = shorepoints[int(len(shorepoints)/2)]
        if (distancePointPoint(testpoint1,ocean_lat_long) < distancePointPoint(testpoint2,ocean_lat_long)) and outTOsea:
            NEWshorepoints = shorepoints2
        elif (distancePointPoint(testpoint1,ocean_lat_long) < distancePointPoint(testpoint2,ocean_lat_long)) and not outTOsea:
            NEWshorepoints = shorepoints3
        elif (distancePointPoint(testpoint1,ocean_lat_long) > distancePointPoint(testpoint2,ocean_lat_long)) and outTOsea:
            NEWshorepoints = shorepoints3
        elif (distancePointPoint(testpoint1,ocean_lat_long) > distancePointPoint(testpoint2,ocean_lat_long)) and not outTOsea:
            NEWshorepoints = shorepoints2
        else:
            NEWshorepoints = shorepoints1



        w.record(shoreRec.record[0],shoreRec.record[1],shoreRec.record[2],shoreRec.record[3])
        w.line([NEWshorepoints])
        
        newshores.append(NEWshorepoints)
    output['TrimmedCorrectedShorelines']=newshores
        
        
    w.close()
    shutil.copy(filepath+"\\"+sitename+"_output-.prj", filepath+"\\"+sitename+"_outputTidalC.prj")
    shoreshape.close()
    
    return output







def GetProjectionInfo(sitename, base_folder, output):      

# this function adds the extent of each image to the output dictionary

  
    
    classificationArraysExtents = []
    SRSs = []
    SGTs = []
    
    # with open(os.path.join(base_folder+ "data\\"+sitename, sitename + '_output' + '.pkl'), 'rb') as f:
    #     output = pickle.load(f) 
    
    
    shore_feature = -1
    for image in output['filename']:
        
        shore_feature = shore_feature+1
        
        # get classified image    
        array_whitewater = output['imClassifs'][shore_feature]
        
        # find image
        aa = glob.glob(base_folder+ "data\\"+sitename+"\\*\\*\\"+image)
        
        # open image
        src = gdal.Open(aa[0])
        SRS = src.GetProjection()
        
        # get extent
        ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()
        lrx = ulx + (src.RasterXSize * xres)
        lry = uly + (src.RasterYSize * yres)
        extent = [ulx, lrx, lry, uly]
        
        # save extent
        classificationArraysExtents.append(extent)
               
        
        
        # get projection info
        SGT = list(src.GetGeoTransform())
        aa = np.shape(array_whitewater)
        bb = np.shape(np.array(src.GetRasterBand(1).ReadAsArray()))
        SGT[1] = SGT[1]* (bb[1]/aa[1])
        SGT[5] = SGT[5]*(bb[0]/aa[0])
        SGT = tuple(SGT)
        SRS = src.GetProjection()
        
        # save arrays as rasters
        # cc_save.Save_Classification_Rasters(sitename, base_folder, image, whitewaterArrays[-1], classArrays[-1], SRS, SGT)
        
        SRSs.append(SRS)
        SGTs.append(SGT)
        
        
    output['SRS'] = SRSs
    output['SGT'] = SGTs
    output['Extents'] = classificationArraysExtents
        
        
    return output

        



def Get_Tidal_DataNOAA3(base_folder, sitename,output,lat,long,utc, a,tideType, USshape, gagesloc):

# this function downloads the tidal elevations from NOAA
# by default it also determines the closest (as the crow flies) tide station to the AOI
# this can be overrriden by using an integer in variable a.
# this integer is dtermined from using the file in the "gagesloc" variable OR in a rerun the user can examine TideStationSelection.png and select another nearby station from the simple map


    datetimeDates = output['dates']
    
    gages = np.genfromtxt(gagesloc,dtype=[('S50'),('S12'),('f8'),('f8')],delimiter=',')
    
    distances = []
    gagelats = []
    gagelongs = []
    for line in gages:
        distances.append(distancePP([line[2],line[3]],[lat,long]))
        gagelats.append(line[2])
        gagelongs.append(line[3])
        
        
        
        
    if int(a) == -1:
        a = np.where(np.array(distances)== np.nanmin(distances))[0][0]
        
        plt.figure(figsize=(10,10))
        
        
        sf = shapefile.Reader(USshape)
        shapes = sf.shapes()
        for shape in shapes:
            plt.scatter(np.array(shape.points)[:,0], np.array(shape.points)[:,1], c='black',s=1)
        plt.scatter(gagelongs, gagelats, s=30,c='cyan')
        
        n=-1
        for all in gagelongs:
            n=n+1
            if (gagelongs[n]>long-0.5 and gagelongs[n]<long+0.5) and (gagelats[n]>lat-0.5 and gagelats[n]<lat+0.5):
                plt.text(gagelongs[n], gagelats[n], str(n))
        
        
        
        sf.close()
        
        plt.scatter(gages[a][3],gages[a][2], s=70,c='blue')
        plt.scatter(long,lat,s=70,c='red')
        plt.axis([long-0.5,long+0.5,lat-0.5,lat+0.5])
#        plt.show()
        plt.savefig(base_folder + 'data\\' + sitename + '\\TideStationSelection.png')
        plt.close('all')
        
        
        
        # print('Is the highlighted gage close enough?')
        # key = input('Type \"yes\" or \"no\"')
        # if key =='yes':
            # pass
        # elif key =='no':
            # a = input('Which gage should be used?')
        
        
        
        
        
    gage = gages[a]
    print('Using gage', a,',',gage[0])
    station = str(gage[1])[2:-1]
    
    
    tides = []
    tidedates = []
    alltides = []
    alltidedates = []
    
    for date in datetimeDates:
        # station = '8454000'
        rangee=False
        if rangee==True:
            beginDateStr = '20130101%2000:00'
            endDateStr = '20130102%2000:00'
            dateStr = 'begin_date='+beginDateStr+'&end_date='+endDateStr
        else:
            
            onedayless = ((date-datetime.timedelta(days=1)))
            onedaymore = ((date+datetime.timedelta(days=1)))
            
            # less
            if onedayless.month<10:
                month = '0'+str(onedayless.month)
            else:
                month = str(onedayless.month)
                
                
            if onedayless.day<10:
                day = '0'+str(onedayless.day)
            else:
                day = str(onedayless.day)
            beginDateStr = str(onedayless.year)+month+day+'%2000:00'
            
            # more
            
            
            if onedaymore.month<10:
                month = '0'+str(onedaymore.month)
            else:
                month = str(onedaymore.month)
                
                
            if onedaymore.day<10:
                day = '0'+str(onedaymore.day)
            else:
                day = str(onedaymore.day)
            endDateStr = str(onedaymore.year)+month+day+'%2000:00'
                
                
                
            dateStr = 'begin_date='+beginDateStr+'&end_date='+endDateStr
            
            
        dateStr = 'begin_date='+beginDateStr[:-8]+'&end_date='+endDateStr[:-8]
        noaaCode = 'https://tidesandcurrents.noaa.gov/api/datagetter?product=predictions&application=NOS.COOPS.TAC.WL&'+dateStr+'&datum='+tideType+'&station='+station+'&time_zone=GMT&units=metric&interval=h&format=xml'
    
        
        data = urllib.request.urlopen(noaaCode)    
        data2 = []
        for line in data:
            data2.append(line)
        data3 = data2[4:-7]
        vs = []
        for line in data3:
            bla = str(line)[31:-7]
            vs.append(float(bla))
        
        
        madeupdates = [datetime.datetime(year=onedayless.year,month=onedayless.month,day=onedayless.day,hour=0,minute=0,tzinfo=utc)]
        for all in vs[1:]:
            madeupdates.append(madeupdates[-1] + datetime.timedelta(minutes=60))
    
        a = np.where(np.array(madeupdates)==nearest(np.array(madeupdates),date))[0][0]
        
        
        tides.append(vs[a])
        tidedates.append(date)
        
#        print(vs[0])
    
        alltides = alltides +vs
        alltidedates = alltidedates + madeupdates
    
    
    
    
    
    if lat > 40 and lat < 50 and long > -92 and long < -75:
        tides = np.zeros(len(tides))
    
    
    
    output['tides'] = tides
    output['tidedates'] = tidedates
    
#    plt.figure(figsize=(20,20))
#    plt.plot(alltidedates, alltides)
#    plt.show()
#    plt.close('all')
    
    return output







def TrimOutputShorelines2(output,filepath,sitename):


# This function cleans up shorelines by looking for large spatial gaps in the sequence. The longest sequence of numbers is considred the real shoreline.
# These gaps are usually caused by features on the shore that end up classified as water.
# coastsat connects them to the edge of the legitimate shoreline. They ruin the appearance of an otherwise good shoreline.
# The function is set to treat something as an illegimate gap if the break is longer than 100 meters.

# this means it is bad practice to try to do an analysis across an inlet, split into two runs instead!


    shoresShapefile = filepath+"\\"+sitename+"_output-.shp"
    shoresShapefileC = filepath+"\\"+sitename+"_outputTrim.shp"
    
    pointDistances = []
    
    
    shoreshape = shapefile.Reader(shoresShapefile)
    shoreRecs = shoreshape.shapeRecords()
    
    w = shapefile.Writer(shoresShapefileC)
    w.fields = shoreshape.fields[1:]    
    
    satfld = FindField(shoreshape.fields, 'satname')
    datefld = FindField(shoreshape.fields, 'date')
    
    
    satdates = []
    for k in range(0,len(output['dates'])):
        m = str(output['dates'][k].month)
        d = str(output['dates'][k].day)
        y = str(output['dates'][k].year)
        if len(m)==1:
            m = '0'+m
        if len(d)==1:
            d = '0'+d
        satdate = output['satname'][k] + y+m+d
        satdates.append(satdate)
    
    
    newshores = []
    for shoreRec in shoreRecs:
        satdate = shoreRec.record[satfld]
        m = str(shoreRec.record[datefld].month)
        d = str(shoreRec.record[datefld].day)
        y = str(shoreRec.record[datefld].year)
        if len(m)==1:
            m = '0'+m
        if len(d)==1:
            d = '0'+d
        satdate = satdate + y+m+d
        
        
        if satdate in satdates:
            
        
        
        
            shorepoints = shoreRec.shape.points
            pointDistances = []
            for n in range(0,len(shorepoints)-1):
                d = distancePP(shorepoints[n],shorepoints[n+1])
                pointDistances.append(d)
                
            
            # plt.scatter(np.array(shorepoints)[:,0], np.array(shorepoints)[:,1])
            # plt.show()
            # plt.close('all')
            
            # plt.scatter(np.arange(0,len(pointDistances)), pointDistances)
            # plt.show()
            # plt.close('all')
            
            breakpoints = [0] + list(np.where(np.array(pointDistances)>100)[0])+[len(shorepoints)]
            lengths = []
            for n in np.flip(np.arange(1,len(breakpoints))):
                lengths.append(breakpoints[n]-breakpoints[n-1])
            lengths = np.flip(np.array(lengths))
            a = np.where(lengths==np.nanmax(lengths))[0][0]
            newShore = shorepoints[breakpoints[a]:breakpoints[a+1]]
    #        print(newShore)
            w.record(shoreRec.record[0],shoreRec.record[1],shoreRec.record[2],shoreRec.record[3])
            w.line([newShore])
            
            newshores.append(newShore)
            
            

    newshores2 = []
    for newshore in newshores:
        newshore2 = []
        for points in newshore:
            newshore2.append(np.array(list(points)))
        newshore2 = np.array(newshore2)
        newshores2.append(newshore2)



        
    output['TrimmedShorelines']=newshores2
        
    w.close()
    shutil.copy(filepath+"\\"+sitename+"_output-.prj", filepath+"\\"+sitename+"_outputTrim.prj")
    
    return output




def UserTransectt(UserTransect):


    transects = {}
    sf = shapefile.Reader(UserTransect)
    shaperecs = sf.shapeRecords()
    n=0
    for shaperec in shaperecs:
        n=n+1
        transects['Transect ' + str(n)] = np.array(shaperec.shape.points)
    sf.close()
    



def NewTransectsBuilder_StartParallel4(Tspace, sitename, base_folder, output):
    
# This function builds transects for the user
# all transects are perpendicular to the reference shoreline in the surrounding region's slope, not the entire shoreline slope
# two sets of transects are built for two different purposes

# the first set issaved as "transects.shp"
# these transects are made every meter along the shoreline
# they are used to shift the shoreline points up or down the beach slope for the tidal adjustment
# that shift is more accurate with more transects
# but there are usually too many for an analysis to take a reasonable amount of time_zone

# which leads us to "transectsSmall.shp"
# for every Tspace (meters) transects above, one of these is added to "transectsSmall.shp"
# these are the transects along which the shoreline intersection analysis is conducted

# several outputs are created by the function which are not used later: transectsRotations, transectsSlopes

# the function uses the classified images in the output dictionary to determine which direction the water is in
# transects are drawn perpendicular to the reference line, equidistant in both directions and then sampled at their endpoints from the classified rasters.
# the results then "vote" on which direction the water is in
# IMPORTANT: because of this, caution should be used in drawing polygons in areas with large lagoons. Make sure there is more water on the "ocean" side than on the "land" side
    
    
    
    filepath = base_folder+'\\data\\'+sitename
    
        
    
    # get image
    
    array_gray = copy.copy(output['imClassifs'][0])
    
#    
#    plt.figure(figsize=(10,10))
#    plt.imshow(array_gray)
#    plt.colorbar()
#    plt.show()
#    plt.close('all')
#    
    

    
    

    
    # open a rster to get extent for transects
    try:
        rasters = glob.glob(filepath+"\\S2\\10m\\*_"+sitename+"_10m.tif")
        src = gdal.Open(rasters[0])
    except:
        rasters = glob.glob(filepath+"\\L8\\pan\\*.tif")
        src = gdal.Open(rasters[0])
    
    ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()
    lrx = ulx + (src.RasterXSize * xres)
    lry = uly + (src.RasterYSize * yres)
    src = None
    
    tryagain = 1
    while lrx-ulx < 1000:
        try:
            src = gdal.Open(rasters[tryagain])
            ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()
            lrx = ulx + (src.RasterXSize * xres)
            lry = uly + (src.RasterYSize * yres)
            src = None
            tryagain = tryagain+1
        except:
            break
    
    
    
    
    shoreRef_shp_filename = filepath+"\\"+sitename+"_reference_shoreline.shp"
    # get reference shapefile points
    sf = shapefile.Reader(shoreRef_shp_filename)
    shapes = sf.shapes()
    points = shapes[0].points
    # less_points = points[1::70]
    sf.close()
    
    
    
    
    
    # add prpidicular points to new transect shapefile
    w = shapefile.Writer(filepath+"\\transects.shp")
    w.field('name', 'C')
    w.field('num', 'C')
    
    w2 = shapefile.Writer(filepath+"\\transectsroots.shp")
    w2.field('name', 'C')
    w2.field('num', 'C')
    
    w3 = shapefile.Writer(filepath+"\\transectsSmall.shp")
    w3.field('name', 'C')
    w3.field('num', 'C')
    
    slope, intercept, r_value, p_value, std_err = st.linregress(np.array(points)[:,0],np.array(points)[:,1])
    if 1 >= slope <= -1 :
        VERT = True
    else:
        VERT = False
    
    
    
    transects = dict([])
    transectsFull = dict([])
    transectsRotations = []
    transectsSlopes = []
    COUNTERtransectsfull=0
    COUNTERtransectssmall=0
    COUNTERtransectssmall2=0
    XXs = []
    YYs = []
    XXXs = []
    YYYs = []
    Xs = []
    Ys = []
    REVERSES = []
    pslopes = []
    skips = 0
    for n in range(5,len(points)-5):
        COUNTERtransectsfull=COUNTERtransectsfull+1
        COUNTERtransectssmall=COUNTERtransectssmall+1
        
        # for the chosen point along the reference shoreline find a slope for best fit line
        deriv_points = np.array(points[n-2:n+2])
        x = deriv_points[:,0]
        y = deriv_points[:,1]
        X = np.array(points)[n,0]
        Y = np.array(points)[n,1]
        slope, intercept, r_value, p_value, std_err = st.linregress(x, y)
        if slope ==0:
            slope = .00000001
        if np.isnan(slope):
            skips=skips+1
            continue
        
        

        
        # find a slope perpindicular to shorelne slope for transect
        pslope = -1*(1/slope)
        
        # start transect with first value
        XX = [X]
#            YY = [Y + pslope*(XX[-1]-X)]
        YY = [Y]
        
        
        # grow transect in forward X direction
        waterPointsForward = []
        while distancePP([XX[0],YY[0]], [XX[-1],YY[-1]]) < 700:
#                XX.append(XX[-1]+1)
#                YY.append(Y + pslope*(XX[-1]-X))
            XX.append(XX[-1] + 1*((1)/(np.sqrt(1+pslope**2))))
            YY.append(YY[-1] + 1*((pslope)/(np.sqrt(1+pslope**2))))
            greyClassification = getArrayValueScaled(XX[-1], YY[-1], array_gray, lry,uly,ulx,lrx)
            if ((greyClassification==2) or (greyClassification==3)):
                waterPointsForward.append(1)
            else:
                waterPointsForward.append(0)
            
            
            
            
            
        # grow transect in backward X direction
        waterPointsReverse = []
        while distancePP([XX[0],YY[0]], [XX[-1],YY[-1]]) < 1400:
#                XX.insert(0, XX[0]-1)
#                YY.insert(0, Y + pslope*(XX[0]-X))
            XX.insert(0,XX[0] - 1*((1)/(np.sqrt(1+pslope**2))))
            YY.insert(0,YY[0] - 1*((pslope)/(np.sqrt(1+pslope**2))))
            greyClassification = getArrayValueScaled(XX[0], YY[0], array_gray, lry,uly,ulx,lrx)
            if ((greyClassification==2) or (greyClassification==3)):
                waterPointsReverse.append(1)
            else:
                waterPointsReverse.append(0)
            
            
        # which direction reaches water first
        if np.nansum(waterPointsForward[0:200])>np.nansum(waterPointsReverse[0:200]):
            REVERSE = False
        if np.nansum(waterPointsForward[0:200])<np.nansum(waterPointsReverse[0:200]):
            REVERSE = True
        else:
            REVERSE=False
            
        if not VERT:
            if pslope < 0:
                XX = np.flip(np.array(XX))
                YY = np.flip(np.array(YY))
                REVERSE = not REVERSE
            
        REVERSES.append(REVERSE)
        XXXs.append(XX)
        YYYs.append(YY)
        Xs.append(X)
        Ys.append(Y)
        pslopes.append(pslope)
            
            
    if REVERSES.count(False) > REVERSES.count(True):
        REVERSE_CONSENSUS = False
    else:
        REVERSE_CONSENSUS = True
        
        
        
        
#    plt.figure(figsize=(20,20))
#    nn = -1
#    for n in range(5,len(points)-5):
#        nn=nn+1
#        XX = XXXs[nn]
#        YY = YYYs[nn]
#        XXa=XX[0]
#        XXb=XX[-1]
#        YYa=YY[0]
#        YYb=YY[-1]
#        plt.scatter(XXa,YYa,s=1,c='red')
#        plt.scatter(XXb,YYb,s=1,c='black')
#    plt.plot(np.array(points)[:,0],np.array(points)[:,1],c='red')
#    plt.gca().set_aspect('equal', adjustable='box')
#    plt.show()
#    plt.close('all')
        
        
        
        
        
    nn = -1
    for n in range(5,len(points)-5-skips):
        nn=nn+1
        XX = XXXs[nn]
        YY = YYYs[nn]
            
        if REVERSE_CONSENSUS:
            XX = np.flip(np.array(XX))
            YY = np.flip(np.array(YY))
            
        XX2 = XX[500:]
        YY2 = YY[500:]
            
        XXs.append(XX2)
        YYs.append(YY2)




        
#    plt.figure(figsize=(20,20))
#    nn = -1
#    for n in range(5,len(points)-5):
#        nn=nn+1
#        XX = XXs[nn]
#        YY = YYs[nn]
#        plt.scatter(XX,YY,s=1)
#    plt.plot(np.array(points)[:,0],np.array(points)[:,1],c='red')
#    plt.gca().set_aspect('equal', adjustable='box')
#    plt.show()
#    plt.close('all')        
        
        
        
        
    
    if len(XXs)==0:
        print('There is something wrong and no transects were created.')
    
    
    c = -1
    COUNTERtransectssmall = -1
    COUNTERtransectssmall2 = 0
    for n in XXs:
        COUNTERtransectssmall = COUNTERtransectssmall+1
        c=c+1
        X = Xs[c]
        XX = XXs[c]
        Y = Ys[c]
        YY = YYs[c]

        x1 = XX[0]
        y1 = YY[0]
        x2 = XX[-1]
        y2 = YY[-1]
        
        
        if np.all(n!=XXs[0]) and distancePP([x1,y1], [XXs[c-1][0],YYs[c-1][1]]) > 20:
            continue
        
        w.line([[ [x1, y1], [x2, y2] ]])
        
        transectsFull['Transect '+str(COUNTERtransectsfull)] = np.array([ [x1, y1], [x2, y2] ])
        
        if slope < 0:
            angle = -1*(np.arctan(slope) - (np.pi/2))
        else:    
            angle = (np.pi/2) - np.arctan(slope)
        rotation = R.from_euler('z', [angle])
        transectsRotations.append(rotation)
        transectsSlopes.append(pslope)
        
        
        
        if COUNTERtransectssmall == Tspace:
            COUNTERtransectssmall=0
            COUNTERtransectssmall2=COUNTERtransectssmall2+1
            transects['Transect '+str(COUNTERtransectssmall2)] = np.array([ [x1, y1], [x2, y2] ])
            w3.line([[ [x1, y1], [x2, y2] ]])
            n2='Transect '+str(COUNTERtransectssmall2)
            c2=str(X)+','+str(Y)
            r = [c2, n2]
            w3.record(*r)
        
        
        n2='Transect '+str(COUNTERtransectsfull)
        c2=str(X)+','+str(Y)
        r = [c2, n2]
        w.record(*r)
        w2.point(x1, y1)
        n2='Transect '+str(COUNTERtransectsfull)
        c2=str(X)+','+str(Y)
        r = [c2, n2]
        w2.record(*r)
        
        
        
        
        

    w.close()
    w2.close()
    w3.close()
    shutil.copyfile(filepath+"\\"+sitename+"_reference_shoreline.prj", filepath+"\\transects.prj")
    shutil.copyfile(filepath+"\\"+sitename+"_reference_shoreline.prj", filepath+"\\transectsroots.prj")
    shutil.copyfile(filepath+"\\"+sitename+"_reference_shoreline.prj", filepath+"\\transectsSmall.prj")
    
    # convert transect shapefile into geoJSON
    shapefileTOgeoJSON_lines(filepath+"\\transects.geojson", filepath+"\\transects.shp")
    
    # convert transectsmall shapefile into geoJSON
    shapefileTOgeoJSON_lines(filepath+"\\transectsSmall.geojson", filepath+"\\transectsSmall.shp")
    
    
    
    
    return filepath+"\\transects.geojson", filepath+"\\transectsSmall.geojson", transects, transectsFull, transectsRotations, transectsSlopes
            
    




def SyncOutputDictShape(output, TCC_File):


# this function makes sure there are no shorelines in the output dictionary that are not in the output shapefile



    
    checkUniques = []
    
    originalkeys = output.keys()
    outputNew = {}
    for originalkey in originalkeys:
        outputNew[originalkey]=[]

    sf = shapefile.Reader(TCC_File)
    shaperecs = sf.shapeRecords()
    for shaperec in shaperecs:
        date = shaperec.record[0]
        sat = shaperec.record[1]
        
        
        done = []
        a = -1
        for outdate in output['dates']:
            a=a+1
            outsat = output['satname'][a]
            code = str(date.year) + str(date.month) + str(date.day) + sat
            if outdate.year==date.year and outdate.month==date.month and outdate.day==date.day and outsat == sat and np.nanmean(output['shorelines'][a]) not in checkUniques and code not in done:
                done.append(code)
                checkUniques.append(np.nanmean(output['shorelines'][a]))
                for originalkey in originalkeys:
                    outputNew[originalkey].append(output[originalkey][a])
    sf.close()
    return outputNew







def RemoveBadImageryLater(base_folder, sitename, output, metadata):

# this function looks at which images are in the "bad" folder and removes them from the output and the metadata


    bad_list = glob.glob(base_folder+'\\data\\'+sitename+'\\jpg_files\\detection\\bad\\*')
    newbads = []
    for bad in bad_list:
        newbad = bad.split('\\')[-1][:16]
        newbads.append(newbad)
    locations = []
    n=-1
    for file in output['filename']:
        n=n+1
        compare = file[:16]
        if not compare in newbads:
            locations.append(n)
    
        
    outputNew = {}
    for key in output:
        listNew = []
        n=-1
        for entry in output[key]:
            n=n+1
            if n in locations:
                listNew.append(entry)
    
        outputNew[key]=listNew
        
        
        
    metadataNew = {}
    for key in metadata:
        satKey = {}
        filenames=[]
        acc_georef=[]
        epsg=[]
        dates=[]
        n=-1
        for date in metadata[key]['dates']:
            n=n+1
            if date in outputNew['dates']:
                filenames.append(metadata[key]['filenames'][n])
                acc_georef.append(metadata[key]['acc_georef'][n])
                epsg.append(metadata[key]['epsg'][n])
                dates.append(metadata[key]['dates'][n])
        outputNew[key]=listNew
        
        satKey['filenames']=filenames
        satKey['acc_georef']=acc_georef
        satKey['epsg']=epsg
        satKey['dates']=dates
    metadataNew[key]=satKey
    
    
    
    
    return outputNew, metadataNew
    
    





def SortImagesSmall(filepath, imageSortPkl):

# this function uses a clustering algorithim to assist the user seperate bad images from good ones
# the user helps "seed" the algorithim by picking 5 good shorelines
# once those are selected the algorithim assesses whether subsequent shorelines fit the pattern of length, centroid, etc
# the function checks in with the user every 50 images to make sure things don't go off the rails


    site = filepath+"\\jpg_files\detection"
    with open(imageSortPkl, 'rb') as f:
        clf = pickle.load(f) 
    
    # reset from prior sorts
    b = glob.glob(site+"\\bad\\*.jpg")
    for bb in b:
        shutil.move(bb)
        
        
    # make bad folder
    try:
        os.mkdir(site+"\\bad")
    except:
        pass
    
    a = glob.glob(site+"\\*.jpg")

    
    sitename = site.split('\\')[-3]
    shapefilename = filepath+'\\'+sitename+'_output-.shp'
    shapefilee = shapefile.Reader(shapefilename)
    shapeRecs = shapefilee.shapeRecords()
    shapedates = []
    for recordd in shapeRecs:
        y=str(recordd.record[0].year)
        m=str(recordd.record[0].month)
        d=str(recordd.record[0].day)
        if len(m)<2:
            m = '0'+m
        if len(d)<2:
            d = '0'+d
        shapedates.append(y+m+d+recordd.record[1])
        
    shapedates = np.array(shapedates)
    
    
    
    # go through images
    l5length=[]
    l5center=[]
    l5lenBreaks=[]
    l5lines=[]
    checkin=0
    for aaa in a:
        checkin=checkin+1
        
        shapedate = aaa.split('\\')[-1].split('-')[0]+aaa.split('\\')[-1].split('-')[1]+aaa.split('\\')[-1].split('-')[2]+aaa.split('\\')[-1].split('-')[-1].split('_')[-1].split('.')[0]
        
        
        
        try:
            h = np.where(shapedates ==shapedate)[0][0]
        except:
            shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
            continue
            
        
        recordd = shapeRecs[h]
        points = recordd.shape.points
        
        
        
        
        
        
        pointDistances = []
        for n in range(0,len(points)-1):
            dd = distancePP(points[n],points[n+1])
            pointDistances.append(dd)
            
        
        breakpoints = [0] + list(np.where(np.array(pointDistances)>100)[0])+[len(points)]
        lengths = []
        for n in np.flip(np.arange(1,len(breakpoints))):
            lengths.append(breakpoints[n]-breakpoints[n-1])
        lengths = np.flip(np.array(lengths))
        g = np.where(lengths==np.nanmax(lengths))[0][0]
        newShore = points[breakpoints[g]:breakpoints[g+1]]
        
        points=copy.copy(newShore)
        breakpoints=len(breakpoints)
        
        
        
        length = LineString(points).length
        centroid = (LineString(points).centroid.x,LineString(points).centroid.y)
        
        
        
        if len(l5length)<5: #want at least x images
            key = GiveUserChoice2(aaa, site)
            if key ==1:
                l5length.append(length)
                l5center.append(centroid)
                l5lenBreaks.append(breakpoints)
                l5lines.append(points)
            if key ==0:
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
            
            
            
            
            
            
            
        elif checkin>=50: # check every once in a while
            key = GiveUserChoice2(aaa, site)
            if key ==1:
                l5length.append(length)
                l5center.append(centroid)
                l5lenBreaks.append(breakpoints)
                l5lines.append(points)
                checkin = 0
            if key ==0:
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])




            
        else: #if its NOT the first few or the checkin....
            testResults = TEST(clf, length, l5length, centroid,l5center,breakpoints,l5lenBreaks,points,l5lines)
            if testResults==2: # if it passes test
                pass
            
            elif testResults==0: # if it fails test
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
                
            else: # if test is unsure
                key = GiveUserChoice2(aaa, site)
                if key ==1:
                    l5length.append(length)
                    l5center.append(centroid)
                    l5lenBreaks.append(breakpoints)
                    l5lines.append(points)
                if key ==0:
                    shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])




        if len(l5length)>5: #only 5 most recent images
            l5length=l5length[-5:]
            l5center=l5center[-5:]
            l5lenBreaks=l5lenBreaks[-5:]
            l5lines=l5lines[-5:]

    shapefilee.close
    
    









def PDIFF(x1,x2):
    return np.abs(x1-x2) / (.5*(x1+x2))
    

def SortImagesSmall2(filepath, output, imageSortPkl):
    site = filepath+"\\jpg_files\detection"
    clf = pickle.load(open(imageSortPkl, 'rb')) 
    sitename = site.split('\\')[-3]
    
    # make bad folder
    try:
        os.mkdir(site+"\\bad")
    except:
        pass
    
    # reset from prior sorts
    b = glob.glob(site+"\\bad\\*.jpg")
    for bb in b:
        shutil.move(bb, site + bb.split('\\')[-1])
    
    a = glob.glob(site+"\\*.jpg")
    
    
    # load output and make dateSat index and pointsList
    shapedates = []
    opoints = []
    ii = -1
    for recordd in range(0, len(output['dates'])):
        ii=ii+1
        y=str(output['dates'][ii].year)
        m=str(output['dates'][ii].month)
        d=str(output['dates'][ii].day)
        if len(m)<2:
            m = '0'+m
        if len(d)<2:
            d = '0'+d
        shapedates.append(y+m+d+output['satname'][ii])
        opoints.append(output['shorelines'][ii].tolist())
    shapedates = np.array(shapedates)
        
    
    
    
    lengthss=[]
    centers1=[]
    centers2=[]
    breaks=[]
    p1s=[]
    p2s=[]
    p3s=[]
    p4s=[]
    
    checkin=0
    
    GOODlengthss=[]
    GOODcenters1=[]
    GOODcenters2=[]
    GOODbreaks=[]
    GOODp1s=[]
    GOODp2s=[]
    GOODp3s=[]
    GOODp4s=[]
    
    # go through images
    
    skipAllSite = False
    
    for aaa in a:
        checkin=checkin+1
        
        shapedate = aaa.split('\\')[-1].split('-')[0]+aaa.split('\\')[-1].split('-')[1]+aaa.split('\\')[-1].split('-')[2]+aaa.split('\\')[-1].split('-')[-1].split('_')[-1].split('.')[0]
        
        
        
        try:
            i = np.where(shapedates == shapedate)[0][0]
        except:
            shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
            continue
            
        
        points = opoints[i]
        imClassif  = output['imClassifs'][i].flatten()
        imClassif = imClassif[~np.isnan(imClassif)]        
        
        
        
        
        
        
        pointDistances = []
        for n in range(0,len(points)-1):
            dd = distancePP(points[n],points[n+1])
            pointDistances.append(dd)
        breakpoints = [0] + list(np.where(np.array(pointDistances)>100)[0])+[len(points)]
        lengths = []
        for n in np.flip(np.arange(1,len(breakpoints))):
            lengths.append(breakpoints[n]-breakpoints[n-1])
        lengths = np.flip(np.array(lengths))
        aa = np.where(lengths==np.nanmax(lengths))[0][0]
        newShore = points[breakpoints[aa]:breakpoints[aa+1]]
        points=copy.copy(newShore)
        breakpoints=len(breakpoints)
        
        
        
        length = LineString(points).length
        try:
            centroid = (LineString(points).centroid.x,LineString(points).centroid.y)
        except:
            centroid = [0,0]
        P1 = len(np.where(imClassif==0)[0])/len(imClassif)
        P2 = len(np.where(imClassif==1)[0])/len(imClassif)
        P3 = len(np.where(imClassif==2)[0])/len(imClassif)
        P4 = len(np.where(imClassif==3)[0])/len(imClassif)
        
        TestArray = [length, centroid[0], centroid[1], breakpoints, P1, P2, P3, P4]
        TestArray = np.array([length, centroid[0], centroid[1], breakpoints])


        
        
        if len(GOODlengthss)<5: #want at least x images
            key = GiveUserChoice2(aaa, site)
            if key ==1:
                GOODlengthss.append(length)
                GOODcenters1.append(centroid[0])
                GOODcenters2.append(centroid[1])
                GOODbreaks.append(breakpoints)
                GOODp1s.append(P1)
                GOODp2s.append(P2)
                GOODp3s.append(P3)
                GOODp4s.append(P4)
            if key ==0:
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
            if key ==2:
                skipAllSite = True
            
            
            
            
            
            
        elif checkin>=50: # check every once in a while
            key = GiveUserChoice2(aaa, site)
            if key ==1:
                GOODlengthss=GOODlengthss[1:]
                GOODcenters1=GOODcenters1[1:]
                GOODcenters2=GOODcenters2[1:]
                GOODbreaks=GOODbreaks[1:]
                GOODp1s=GOODp1s[1:]
                GOODp2s=GOODp2s[1:]
                GOODp3s=GOODp3s[1:]
                GOODp4s=GOODp4s[1:]
                
                GOODlengthss.append(length)
                GOODcenters1.append(centroid[0])
                GOODcenters2.append(centroid[1])
                GOODbreaks.append(breakpoints)
                GOODp1s.append(P1)
                GOODp2s.append(P2)
                GOODp3s.append(P3)
                GOODp4s.append(P4)
                checkin = 0
            if key ==0:
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])




            
        else: #if its NOT the first few or the checkin run the test
            Glengths=np.nanmean(GOODlengthss)
            Gcenters1=np.nanmean(GOODcenters1)
            Gcenters2=np.nanmean(GOODcenters2)
            Gbreaks=np.nanmean(GOODbreaks)
            Gp1s=np.nanmean(GOODp1s)
            Gp2s=np.nanmean(GOODp2s)
            Gp3s=np.nanmean(GOODp3s)
            Gp4s=np.nanmean(GOODp4s)
            
            GoodArray = [Glengths, Gcenters1, Gcenters2, Gbreaks]
            
            TEST = list(PDIFF(np.array(TestArray),np.array(GoodArray)))       
            
            print('--')
            print(TEST)
            
            testResults = clf.predict([TEST])[0]         
            print(testResults)
            if testResults==1: # if it passes test
                pass
            elif testResults==0: # if it fails test
                shutil.move(aaa, site+"\\bad\\"+aaa.split('\\')[-1])
                
        if skipAllSite:
            b = glob.glob(site+"\\bad\\*.jpg")
            for bb in b:
                shutil.move(bb, site + bb.split('\\')[-1])
            break



























def geojsonTOshp_lines(geojson, shp):
    a = "ogr2ogr -nlt LINESTRING -skipfailures -overwrite "
    b = shp + " "
    c = geojson
    # d = " "
    # d = "OGRGeoJSON"
    clipString = a + b + c# + d + e
    subprocess.call(clipString)







def FindEPSG(polygon):
    point = polygon[0][1]
    
    a = np.array([[32601,-180.0000,0.0000,-174.0000,84.0000],
    [32602,-174.0000,0.0000,-168.0000,84.0000],
    [32603,-168.0000,0.0000,-162.0000,84.0000],
    [32604,-162.0000,0.0000,-156.0000,84.0000],
    [32605,-156.0000,0.0000,-150.0000,84.0000],
    [32606,-150.0000,0.0000,-144.0000,84.0000],
    [32607,-144.0000,0.0000,-138.0000,84.0000],
    [32608,-138.0000,0.0000,-132.0000,84.0000],
    [32609,-132.0000,0.0000,-126.0000,84.0000],
    [32610,-126.0000,0.0000,-120.0000,84.0000],
    [32611,-120.0000,0.0000,-114.0000,84.0000],
    [32612,-114.0000,0.0000,-108.0000,84.0000],
    [32613,-108.0000,0.0000,-102.0000,84.0000],
    [32614,-102.0000,0.0000,-96.0000,84.0000],
    [32615,-96.0000,0.0000,-90.0000,84.0000],
    [32616,-90.0000,0.0000,-84.0000,84.0000],
    [32617,-84.0000,0.0000,-78.0000,84.0000],
    [32618,-78.0000,0.0000,-72.0000,84.0000],
    [32619,-72.0000,0.0000,-66.0000,84.0000],
    [32620,-66.0000,0.0000,-60.0000,84.0000],
    [32621,-60.0000,0.0000,-54.0000,84.0000],
    [32622,-54.0000,0.0000,-48.0000,84.0000],
    [32623,-48.0000,0.0000,-42.0000,84.0000],
    [32624,-42.0000,0.0000,-36.0000,84.0000],
    [32625,-36.0000,0.0000,-30.0000,84.0000],
    [32626,-30.0000,0.0000,-24.0000,84.0000],
    [32627,-24.0000,0.0000,-18.0000,84.0000],
    [32628,-18.0000,0.0000,-12.0000,84.0000],
    [32629,-12.0000,0.0000,-6.0000,84.0000],
    [32630,-6.0000,0.0000,0.0000,84.0000],
    [32631,0.0000,0.0000,6.0000,84.0000],
    [32632,6.0000,0.0000,12.0000,84.0000],
    [32633,12.0000,0.0000,18.0000,84.0000],
    [32634,18.0000,0.0000,24.0000,84.0000],
    [32635,24.0000,0.0000,30.0000,84.0000],
    [32636,30.0000,0.0000,36.0000,84.0000],
    [32637,36.0000,0.0000,42.0000,84.0000],
    [32638,42.0000,0.0000,48.0000,84.0000],
    [32639,48.0000,0.0000,54.0000,84.0000],
    [32640,54.0000,0.0000,60.0000,84.0000],
    [32641,60.0000,0.0000,66.0000,84.0000],
    [32642,66.0000,0.0000,72.0000,84.0000],
    [32643,72.0000,0.0000,78.0000,84.0000],
    [32644,78.0000,0.0000,84.0000,84.0000],
    [32645,84.0000,0.0000,90.0000,84.0000],
    [32646,90.0000,0.0000,96.0000,84.0000],
    [32647,96.0000,0.0000,102.0000,84.0000],
    [32648,102.0000,0.0000,108.0000,84.0000],
    [32649,108.0000,0.0000,114.0000,84.0000],
    [32650,114.0000,0.0000,120.0000,84.0000],
    [32651,120.0000,0.0000,126.0000,84.0000],
    [32652,126.0000,0.0000,132.0000,84.0000],
    [32653,132.0000,0.0000,138.0000,84.0000],
    [32654,138.0000,0.0000,144.0000,84.0000],
    [32655,144.0000,0.0000,150.0000,84.0000],
    [32656,150.0000,0.0000,156.0000,84.0000],
    [32657,156.0000,0.0000,162.0000,84.0000],
    [32658,162.0000,0.0000,168.0000,84.0000],
    [32659,168.0000,0.0000,174.0000,84.0000],
    [32660,174.0000,0.0000,180.0000,84.0000],
    [32701,-180.0000,-80.0000,-174.0000,0.0000],
    [32702,-174.0000,-80.0000,-168.0000,0.0000],
    [32703,-168.0000,-80.0000,-162.0000,0.0000],
    [32704,-162.0000,-80.0000,-156.0000,0.0000],
    [32705,-156.0000,-80.0000,-150.0000,0.0000],
    [32706,-150.0000,-80.0000,-144.0000,0.0000],
    [32707,-144.0000,-80.0000,-138.0000,0.0000],
    [32708,-138.0000,-80.0000,-132.0000,0.0000],
    [32709,-132.0000,-80.0000,-126.0000,0.0000],
    [32710,-126.0000,-80.0000,-120.0000,0.0000],
    [32711,-120.0000,-80.0000,-114.0000,0.0000],
    [32712,-114.0000,-80.0000,-108.0000,0.0000],
    [32713,-108.0000,-80.0000,-102.0000,0.0000],
    [32714,-102.0000,-80.0000,-96.0000,0.0000],
    [32715,-96.0000,-80.0000,-90.0000,0.0000],
    [32716,-90.0000,-80.0000,-84.0000,0.0000],
    [32717,-84.0000,-80.0000,-78.0000,0.0000],
    [32718,-78.0000,-80.0000,-72.0000,0.0000],
    [32719,-72.0000,-80.0000,-66.0000,0.0000],
    [32720,-66.0000,-80.0000,-60.0000,0.0000],
    [32721,-60.0000,-80.0000,-54.0000,0.0000],
    [32722,-54.0000,-80.0000,-48.0000,0.0000],
    [32723,-48.0000,-80.0000,-42.0000,0.0000],
    [32724,-42.0000,-80.0000,-36.0000,0.0000],
    [32725,-36.0000,-80.0000,-30.0000,0.0000],
    [32726,-30.0000,-80.0000,-24.0000,0.0000],
    [32727,-24.0000,-80.0000,-18.0000,0.0000],
    [32728,-18.0000,-80.0000,-12.0000,0.0000],
    [32729,-12.0000,-80.0000,-6.0000,0.0000],
    [32730,-6.0000,-80.0000,0.0000,0.0000],
    [32731,0.0000,-80.0000,6.0000,0.0000],
    [32732,6.0000,-80.0000,12.0000,0.0000],
    [32733,12.0000,-80.0000,18.0000,0.0000],
    [32734,18.0000,-80.0000,24.0000,0.0000],
    [32735,24.0000,-80.0000,30.0000,0.0000],
    [32736,30.0000,-80.0000,36.0000,0.0000],
    [32737,36.0000,-80.0000,42.0000,0.0000],
    [32738,42.0000,-80.0000,48.0000,0.0000],
    [32739,48.0000,-80.0000,54.0000,0.0000],
    [32740,54.0000,-80.0000,60.0000,0.0000],
    [32741,60.0000,-80.0000,66.0000,0.0000],
    [32742,66.0000,-80.0000,72.0000,0.0000],
    [32743,72.0000,-80.0000,78.0000,0.0000],
    [32744,78.0000,-80.0000,84.0000,0.0000],
    [32745,84.0000,-80.0000,90.0000,0.0000],
    [32746,90.0000,-80.0000,96.0000,0.0000],
    [32747,96.0000,-80.0000,102.0000,0.0000],
    [32748,102.0000,-80.0000,108.0000,0.0000],
    [32749,108.0000,-80.0000,114.0000,0.0000],
    [32750,114.0000,-80.0000,120.0000,0.0000],
    [32751,120.0000,-80.0000,126.0000,0.0000],
    [32752,126.0000,-80.0000,132.0000,0.0000],
    [32753,132.0000,-80.0000,138.0000,0.0000],
    [32754,138.0000,-80.0000,144.0000,0.0000],
    [32755,144.0000,-80.0000,150.0000,0.0000],
    [32756,150.0000,-80.0000,156.0000,0.0000],
    [32757,156.0000,-80.0000,162.0000,0.0000],
    [32758,162.0000,-80.0000,168.0000,0.0000],
    [32759,168.0000,-80.0000,174.0000,0.0000],
    [32760,174.0000,-80.0000,180.0000,0.0000]])
    
    for all in a:
        if point[0]>all[1] and point[0]<all[3] and point[1]>all[2] and point[1]<all[4]:
            epsg = all[0]
    
    return int(epsg)

































# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY
# NOT CALLED DIRECTLY




def FindField(fieldsw, find):
# this function figures out which entry in a shapefile's attribute table is the one the user is looking for

    idx=-1
    for field in fieldsw[1:]:
        idx=idx+1
        if field[0] == find:
            break
    return idx






def lengthTest(length, l5length):
    l5length = np.array(l5length)
    lengthpercents = (length-l5length)/l5length
    return lengthpercents
    
    
def centroidTest(centroid,l5center):
    l5center = np.array(l5center)
    distances=(np.sqrt((centroid[0]-l5center[:,0])**2+(centroid[1]-l5center[:,1])**2))
    return distances
    
def hausdorffTest(points, l5lines):
    u = points
    distances = []
    for v in l5lines:
        distances.append(np.nanmax([directed_hausdorff(u, v)[0], directed_hausdorff(v, u)[0]]))
    return np.array(distances)
    
def breaksTest(breakpoints,lenBreaks):
    #test for good
    breakmean= np.nanmean(lenBreaks)
    breaksd = np.std(lenBreaks) # if true its good
    breaks = (breakmean*np.ones(len(lenBreaks))+2*breaksd>breakpoints) & (breakmean*np.ones(len(lenBreaks))-2*breaksd<breakpoints) | (np.nanmax(lenBreaks)*np.ones(len(lenBreaks))==breakpoints) | (np.nanmin(lenBreaks)*np.ones(len(lenBreaks))==breakpoints)
    breaks=np.array(breaks)
    
    return breaks.all()




def TEST(clf, length, l5length, centroid,l5center,breakpoints,l5lenBreaks,points,l5lines):
    lengthResult = lengthTest(length, l5length)
    centroidResult = centroidTest(centroid,l5center)
    breakResult = breaksTest(breakpoints,l5lenBreaks)
    hausdorffResult = hausdorffTest(points,l5lines)
    
#    print(lengthResult)
#    print(centroidResult)
#    print(breakResult)
#    print(hausdorffResult)
    
    percentgood = 0.019
    percentbad = 0.25
    
    cdistancegood = 75
    cdistancebad = 400
    
    hdistancegood = 50
    hdistancebad = 500
    
    lengthgeneralgood = (lengthResult<percentgood).any()
    centroidgeneralgood = (centroidResult<cdistancegood).any()
    hausdorffgeneralgood =(hausdorffResult<hdistancegood).any()
    
    lengthgeneralbad = (lengthResult>percentbad).all()
    centroidgeneralbad = (centroidResult>cdistancebad).all()
    hausdorffgeneralbad = (hausdorffResult>hdistancebad).all()
    
    
#    ZZ = []
#    for n in range(0, len(lengthResult)):
#        zz = clf.predict(np.array([lengthResult[n], hausdorffResult[n]]))
#        ZZ.append(zz)
        
    zz = clf.predict(np.dstack((lengthResult, hausdorffResult))[0])
    
    
    if np.nansum(zz) == len(zz):
        result = 2
    elif np.nansum(zz) == 0:
        result = 0
    else:
        result = 1
    
    return result
    
    







def distancePointPoint(point1, point2):
    distance = (np.sqrt((point1[0]-point2[0])**2+(point1[1]-point2[1])**2))
    return distance



def distancePP(point1, point2):
    distances=(np.sqrt((point1[0]-point2[0])**2+(point1[1]-point2[1])**2))
    return distances

def nearest(items, pivot):
    return min(items, key=lambda x: abs(x - pivot))

def getArrayValueScaled(x, y, array, lry,uly,ulx,lrx):
    xpercent = (x-ulx)/(lrx-ulx)
    ypercent = (y-lry)/(uly-lry)
    ypercent = 1-ypercent
    C = xpercent*array.shape[1]
    R = ypercent*array.shape[0]
    C = int(C)
    R = int(R)
    try:
        arrayValue = array[R,C]
    except:
        arrayValue = 0
    return arrayValue




def shapefileTOgeoJSON_lines(geojson, shp):
    # a = "ogr2ogr -f \"GeoJSON\" -t_srs "
    # b = shp + " "
    # c = geojson + " "
    # # d = " "
    # # d = "ESRI Shapefile"
    # clipString = a + c + b# + d + e
    # # print(clipString)
    # subprocess.call(clipString)    
    a = "ogr2ogr -nlt LINESTRING -skipfailures "
    b = geojson + " "
    c = shp
    # d = " "
    # d = "OGRGeoJSON"
    clipString = a + b + c# + d + e
    subprocess.call(clipString)


    

def GiveUserChoice2(aaa, site):    
    img = mpimg.imread(aaa)




    fig = plt.figure()
    fig.set_size_inches([18, 9])
    mng = plt.get_current_fig_manager()
    mng.window.showMaximized()



    # create image 1 (RGB)
    plt.imshow(img)
    plt.title(site, fontweight='bold', fontsize=16)



    # set a key event to accept/reject the detections (see https://stackoverflow.com/a/15033071)
    # this variable needs to be immuatable so we can access it after the keypress event
    key_event = {}
    def press(event):
        # store what key was pressed in the dictionary
        key_event['pressed'] = event.key
    # let the user press a key, right arrow to keep the image, left arrow to skip it
    # to break the loop the user can press 'escape'
    while True:
        btn_keep = plt.text(1.1, 0.9, 'keep ', size=12, ha="right", va="top",   bbox=dict(boxstyle="square", ec='k',fc='w'))
        btn_skip = plt.text(-0.1, 0.9, ' trash', size=12, ha="left", va="top",   bbox=dict(boxstyle="square", ec='k',fc='w'))
        btn_esc = plt.text(0.5, 0, '<esc> to quit', size=12, ha="center", va="top",  bbox=dict(boxstyle="square", ec='k',fc='w'))
        plt.draw()
        fig.canvas.mpl_connect('key_press_event', press)
        plt.waitforbuttonpress()
        # after button is pressed, remove the buttons
        btn_skip.remove()
        btn_keep.remove()
        btn_esc.remove()
        
 # keep/skip image according to the pressed key, 'escape' to break the loop
        if key_event.get('pressed') == 'left':
            skip_image = 0
            break
        elif key_event.get('pressed') == 'right':
            skip_image = 1
            break
        elif key_event.get('pressed') == '.':
            skip_image = 2
            break
        else:
            plt.waitforbuttonpress()


    plt.close('all')
    
    
    return skip_image



    
    







